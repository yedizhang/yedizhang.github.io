<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: sans-serif; 
		font-weight:400;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:28px;
		font-weight:400;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #2268c3;
		text-decoration: none;
	}
	a:hover {
		color: #2268c3;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>


<html>
<head>
	<title>Understanding Unimodal Bias in Multimodal Deep Linear Networks</title>
	<meta property="og:image" content="./img/unimodal-bias/L2_late_feat.gif"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Understanding Unimodal Bias in Multimodal Deep Linear Networks" />
	<meta property="og:description" content="We study multimodal deep linear networks and show that late and intermediate fusion architectures can give rise to long unimodal phases and permanent unimodal bias." />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EJGLRC78GK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EJGLRC78GK');
</script>
<!-- Global site tag (gtag.js) - Google Analytics -->
</head>

<body>
	<br>
	<center>
		<span style="font-size:32px;font-weight:400">Understanding Unimodal Bias in Multimodal Deep Linear Networks</span>	
		<table align=center width=600px>
			<table align=center width=600px>
				<tr><span style="font-size:20px;font-weight:400">ICML 2024</span></tr>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px"><a href="https://yedizhang.github.io/">Yedi Zhang</a><sup>1</sup></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px"><a href="https://www.gatsby.ucl.ac.uk/~pel/">Peter Latham</a><sup>1</sup></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px"><a href="https://www.saxelab.org/people/andrewsaxe/">Andrew Saxe</a><sup>1,2</sup></span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=250px>
				<tr>
					<center>
						1: Gatsby Computational Neuroscience Unit, University College London <br>
						2: Sainsbury Wellcome Centre, University College London
					</center>
				</tr>
				<tr><br></tr>
			</table>
			<table align=center width=160px>
				<tr>
					<td align=center width=80px>
						<center>
							<span><a href="https://arxiv.org/abs/2312.00935"><img style="width:40px" src="img/doc-mark.svg" alt="arxiv"/></a></span>
						</center>
					</td>
					<td align=center width=80px>
						<center>
							<span><a href="https://github.com/yedizhang/unimodal-bias"><img style="width:40px" src="img/github-mark.svg" alt="github"/></a></span>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>
	
	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Using multiple input streams simultaneously to train multimodal neural networks is intuitively advantageous but practically challenging. A key challenge is unimodal bias, where a network overly relies on one modality and ignores others during joint training. We develop a theory of unimodal bias with multimodal deep linear networks to understand how architecture and data statistics influence this bias. This is the first work to calculate the duration of the unimodal phase in learning as a function of the depth at which modalities are fused within the network, dataset statistics, and initialization. We show that the deeper the layer at which fusion occurs, the longer the unimodal phase. A long unimodal phase can lead to a generalization deficit and permanent unimodal bias in the overparametrized regime. Our results, derived for multimodal linear networks, extend to nonlinear networks in certain settings. Taken together, this work illuminates pathologies of multimodal learning under joint training, showing that late and intermediate fusion architectures can give rise to long unimodal phases and permanent unimodal bias.
			</td>
		</tr>
	</table>
	
	<br>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/L2_early_feat.gif"/>
					</center>
				</td>
			</tr>
			<tr>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/L2_late_feat.gif"/>
					</center>
				</td>
			</tr>

		</table>
		<table align=center width=850px>
			<tr>
				<td>
					<center>
						Loss and weights trajectories of early fusion (upper row) and late fusion (lower row) linear networks.
					</center>
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<center><h1>Supplementary Material</h1></center>
	<details>
		<summary>Effect of positive/negative correlations between modalities</summary>
		<table align=center width=900px>
			<tr>
				<td width=50px></td>
				<td align=center width=400px>Early fusion linear network</td>
				<td width=20px></td>
				<td align=center width=400px>Late fusion linear network</td>
			</tr>
			<tr>
				<td width=50px>Positive correlation</td>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/L2_early_rho0.5_feat.gif"/>
					</center>
				<td width=20px></td>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/L2_late_rho0.5_feat.gif"/>
					</center>
				</td>
			</tr>
			<tr>
				<td width=50px>Negative correlation</td>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/L2_early_rho-0.5_feat.gif"/>
					</center>
				<td width=20px></td>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/L2_late_rho-0.5_feat.gif"/>
					</center>
				</td>
			</tr>
		</table>
	</details>

	<details>
		<summary>Nonlinear network and heterogeneous task</summary>
		We present a simple heterogeneous task: y=x<sub>A</sub> + XOR(x<sub>B</sub>) where x<sub>A</sub> is a scalar and x<sub>B</sub>∈{[1,1], [1,-1],[-1,1], [-1,-1]}. XOR(x<sub>B</sub>) refers to performing XOR to the two dimensions of x<sub>B</sub>. We plot the loss and weights trajectories for different variances of x<sub>A</sub>.
		<table align=center width=900px>
			<tr>
				<td width=50px></td>
				<td align=center width=400px>Early fusion ReLU network</td>
				<td width=20px></td>
				<td align=center width=400px>Late fusion ReLU network</td>
			</tr>
			<tr>
				<td width=50px>σ<sub>A</sub>=1</td>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/ReLU_L2_early_xor_var1_feat.gif"/>
					</center>
				<td width=20px></td>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/ReLU_L2_late_xor_var1_feat.gif"/>
					</center>
				</td>
			</tr>
			<tr>
				<td width=50px>σ<sub>A</sub>=2</td>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/ReLU_L2_early_xor_var2_feat.gif"/>
					</center>
				<td width=20px></td>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/ReLU_L2_late_xor_var2_feat.gif"/>
					</center>
				</td>
			</tr>
			<tr>
				<td width=50px>σ<sub>A</sub>=3</td>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/ReLU_L2_early_xor_var3_feat.gif"/>
					</center>
				<td width=20px></td>
				<td width=400px>
					<center>
						<img class="round" style="width:400px" src="./img/unimodal-bias/ReLU_L2_late_xor_var3_feat.gif"/>
					</center>
				</td>
			</tr>
		</table>
		We observe that two-layer late fusion ReLU networks always learn this task successfully, forming the four perpendicular XOR features. However, two-layer early fusion ReLU networks do not learn consistent XOR features and can even fail to learn this task. In the failed cases, the variance of x<sub>A</sub> is large so that the network can be stuck at a local minimum where the network only exploits the linear modality. For this heterogeneous task, late fusion networks are advantageous in terms of extracting heterogeneous features from each input modality.
	</details>


	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<center>
					This webpage template is borrowed from <a href="https://github.com/richzhang/webpage-template">here</a>.
				</center>
			</td>
		</tr>
	</table>

</body>
</html>
